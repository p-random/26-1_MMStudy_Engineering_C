# 2주차 정리

**빅데이터를 지탱하는 기술 - 니시다 케이스케**

- 2주차 범위 : 1p ~ 22p(1-1, 1-2), 132p ~ 153p(4-1, 4-2)

## CHAPTER1 - 빅데이터의 기초 지식

### 1-1. [배경] 빅데이터의 정착

- 빅데이터가 정착한 배경
  1. 클라우드 서비스의 보급으로 기술적 제약이 적어져 누구나 데이터 분석 가능
  2. 많은 기업들이 데이터 처리에 분산 시스템 도입

- 빅데이터의 취급이 어려운 이유
  1. 데이터의 분석 방법을 모름
  2. 데이터 처리에 수고와 시간이 걸림

- 빅데이터 기술
  - 전통적인 관계형 데이터베이스로는 취급할 수 없을 만큼 대량의 데이터가 쌓임
  - 축적된 데이터를 처리하기 위해 기존과는 다른 구조가 필요했음
    1.  Hadoop

        : 다수의 컴퓨터에서 대량의 데이터를 처리하기 위한 시스템
        - 구글에서 개발된 분산 처리 프레임워크인 'MapReduce'를 참고해 제작됨
        - 초기 Hadoop은 자바 언어로 프로그래밍해야 했음
        - SQL과 같은 쿼리 언어로 실행하기 위해 Hive가 개발되어 출시됨
        - Hive의 도입으로 많은 사람이 프로그래밍 없이 Hadoop을 이용한 분산 시스템의 혜택을 받음

    2.  NoSQL 데이터베이스

        : 전통적인 RDB의 제약을 제거하는 것을 목표로 한 데이터베이스
        - key-value store : 다수의 키와 값을 관련지어 저장
        - document store : JSON과 같은 복잡한 데이터 구조를 저장
        - wide-column store : 여러 키를 사용해 높은 확장성을 제공

        - RDB보다 고속의 읽기, 쓰기가 가능하고 분산 처리에 뛰어남
        - 모여진 데이터를 나중에 집계하는 것이 목적인 Hadoop과 다르게 애플리케이션에서 온라인으로 접속하는 데이터베이스

          -> NoSQL 데이터베이스에 기록하고 + Hadoop으로 분산 처리하는 조합이 대규모 데이터를 현실적인 비용으로 다룰 수 있게 해 줌

- 데이터 웨어하우스 변화
  - 예전

    : 업무시스템 -> RDB -> 데이터웨어하우스(늘어나는데이터)

  - 데이터 증가

    : 업무시스템 -> RDB -> **Hadoop** -> 데이터웨어하우스

    -> 확장성이 뛰어난 Hadoop에 데이터 처리를 맡김으로써 데이터웨어하우스의 부하를 줄임

- 스몰 데이터

  : 한 대의 노트북에서도 처리 가능한 소규모 데이터로, 기존 분석 기술만으로도 충분히 다룰 수 있음
  - 데이터의 양이 증가하면 처리 시간이 급격히 증가하며, 데이터의 양이 적을 경우 스몰 데이터 기술이 더 우수함

- 데이터 디스커버리 기초 지식
  - 데이터 디스커버리: 데이터 웨어하우스에 저장된 데이터를 시각화하려는 방법으로, 대화형으로 데이터를 시각화하여 가치 있는 정보를 찾으려고 하는 과정
  - 데이터 디스커버리는 '셀프서비스용 BI 도구'로 불림
  - BI 도구(Business intelligence tool) : 경영자용 시각화 시스템으로, 대규모의 도구
  - 셀프서비스용 BI 도구 : BI 도구를 개인도 사용할 수 있게 단순화한 것

  -> 느낀 점 : 데이터 규모, 목적, 실시간성에 맞는 도구를 알맞게 선택하는 능력이 중요할 것이라는 생각이 들었음

### 1-2. 빅데이터 시대의 데이터 분석 기반

- 빅데이터의 기술
  - 데이터 파이프라인

    : 일반적으로 차례대로 전달해나가는 데이터로 구성된 시스템
    <p></p>

  - 데이터 수집
    - 데이터는 여러 장소에서 발생하며 각각 다른 형태를 보임
    - 각각 서로 다른 기술로 데이터를 전송하는데, 크게 2가지가 있음
      1. 벌크(bulk) 형

         : 이미 어딘가 존재하는 데이터를 정리해 추출하는 방법
         - 데이터베이스, 파일 서버 등에서 정기적으로 수집하는 데 사용

      2. 스트리밍(streaming) 형

         : 차례차례로 생성되는 데이터를 끊임없이 계속해서 보내는 방법
         - 모바일 앱, 임베디드 장비 등에서 널리 수집하는 데 사용

    <p></p>

  - 스트림 처리와 배치 처리
    - 스트림 처리(stream processing)

      : 스트리밍 형 방법으로 받은 데이터를 실시간으로 처리

    - 배치 처리(batch processing)

      : 어느 정도 정리된 데이터를 모아 효율적으로 가공

      <p></p>

  - 분산 스토리지

    : 여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템
    - 대표적으로, 한 덩어리로 모인 데이터에 이름을 부여해 파일로 저장하는 **객체 스토리지**가 있음 (Amazon S3)
    <p></p>

  - 분산 데이터 처리
    - 분산 스토리지에 저장된 데이터를 처리하는 데 분산 데이터 처리의 프레임워크가 필요함
    - 빅데이터를 SQL로 집계하는 두 가지 방법
      1.  쿼리 엔진 도입
          - 예시로 Hive가 있고, 더 고속인 대화형 쿼리 엔진도 개발됨
      2.  외부의 데이터 웨어하우스 제품 이용
          - 분산 스토리지에서 데이터를 추출한 뒤, 데이터 웨어하우스에 적합한 방식으로 변환하여 적재함
          - 이 절차를 ETL 프로세스라고 함

            => ETL 프로세스 (Extract -> Transform -> Load)

    <p></p>

  - 워크플로 관리
    - 전체 데이터 파이프라인 동작을 관리하기 위함
    - 매일 정해진 시간에 배치 처리를 스케줄대로 실행하고,
      오류가 발생한 경우에는 관리자에게 통지하는 목적으로 사용됨
    - ETL : 데이터베이스 바깥에서 데이터를 가공
    - ELT : 데이터를 읽어 들인 후에 가공

<p></p>

- 데이터 웨어하우스와 데이터 마트
  - 데이터 웨어하우스
    - 대량의 데이터를 장기 보존하는 것에 최적화되어 있음
    - 소량의 데이터를 자주 쓰고 읽는 데는 적합하지 않음

    [용어]
    - 데이터 소스
      : 업무 시스템을 위한 RDB나 로그 등을 저장하는 파일 서버
    - 로우 데이터
      : 데이터 소스에 보존된 원시 데이터
    - ETL 프로세스
      : 로우 데이터를 추출하고 필요에 따라 가공한 후 데이터 웨어하우스에 저장하기까지의 흐름

  - 데이터 마트
    - 데이터 웨어하우스에서 필요한 데이터만을 추출하여 데이터 마트를 구축함
    - BI 도구와 조합시키는 형태로 데이터를 시각화하는 데에도 사용됨

<p></p>

- 데이터 레이크

  : 여러 곳에서 흘러들어 오는 데이터를 축적해 두는 데이터의 축적 장소
  - 데이터 형식 자유지만, 대부분 CSV나 JSON 사용
  - 모든 데이터를 그대로 저장하고, 나중에 필요한 것만을 꺼내서 사용함

  - 데이터 레이크는 단순한 스토리지라서, 이것만으로 데이터 가공 불가능
  - 그래서 분산 데이터 처리 기술(MapReduce 등)을 사용해서 가공, 집계한 뒤
    데이터 마트로 추출하여 분석을 진행할 수 있음

- 애드 혹 분석 및 대시보드 도구
  - 애드 혹 분석

    : 수작업으로 데이터를 집계하는 일회성 데이터 분석
    - 예 :
      - SQL 쿼리를 직접 작성해 실행
      - 스프레드시트에서 그래프 만들기

  - 대시보드 도구

    : 정기적으로 그래프와 보고서를 만들고 싶을 때 사용
    - 설정한 스케줄에 따라 쿼리를 실행해 그 결과로부터 그래프 생성 가능

- 빅데이터를 다루는 도구 선택의 두 가지 힌트
  1. 저장할 수 있는 데이터 용량에 제한이 없을 것
  2. 데이터를 효율적으로 추출할 수단이 있을 것
  - 데이터 파이프라인 전체의 기본적인 흐름은 변하지 않음
  - 기술은 시대에 따라 달라지며, 분석 환경은 계속 발전하고 있음

    => 전체의 흐름을 총괄하는 워크플로 관리가 중요해지고 있음

- 데이터 마트와 워크플로 관리
  - 복잡한 데이터 분석에서는 먼저 데이터 마트를 구축하고 분석하거나 시각화함
  - 특히 BI 도구(시각화)를 사용할 경우 데이터 마트는 거의 필수적임
  - 데이터 마트 구축은 배치 처리로 자동화되는 경우가 많기 때문에,
    실행 관리를 위해 워크플로 관리 도구를 사용함
  - 데이터 처리를 자동화해서 장기 운용을 위해서는 안정된 워크플로 관리가 필수적임

<p></p>

## CHAPTER4 - 빅데이터의 축적

### 4-1. 벌크 형과 스트리밍 형의 데이터 수집

- 객체 스토리지

  : 대량의 파일을 저장하기 위한 확장성 높은 분산 스토리지 방식
  - 데이터는 항상 여러 디스크에 복사되기 때문에 일부 하드웨어가 고장 나더라도 데이터가 손실되지 않음
  - 데이터양이 많을 때는 우수하지만, 소량의 데이터는 비효율적이라 주의가 필요함

- 데이터 수집

  : 수집한 데이터를 가공해 집계 효율이 좋은 분산 스토리지를 만드는 일련의 프로세스
  - 시계열 데이터

    : 시간과 함께 생성되는 데이터
    - 수시로 객체 스토리지에 기록하면 -> 대량의 작은 파일 생성 -> 성능 저하시키는 요인

    - 작은 데이터를 모아서 -> 하나의 큰 파일로 만듦으로써 효율 높임

  - 파일이 매우 큰 경우

    -> 네트워크 전송에 시간이 걸림

    -> 거대한 데이터는 적당히 나눔으로써 문제 발생을 줄임

  - 객체 스토리지에서 효율적으로 처리할 수 있는 파일 크기
    - 대략 1MB ~ 1GB

- 벌크 형의 데이터 전송
  - 전통적인 데이터 웨어하우스에서 주로 사용되던 방식
  - 데이터베이스 / 파일 서버 / 웹 서비스 등에서 SQL, API 등의 방식으로 정리된 데이터를 추출함
  - 데이터가 처음부터 분산 스토리지에 저장되어 있지 않은 경우, 데이터 전송을 위한 **ETL 서버**를 설치함
    - **ETL 서버**에는 ETL 도구, 오픈 소스 벌크 전송 도구, 또는 직접 작성한 스크립트 등을 이용해 데이터를 전송함
  - 데이터 전송의 신뢰성이 중요한 경우에 적합함
    - 문제가 발생해도 데이터 전송을 재실행할 수 있음
  - 워크플로 관리 도구와 궁합이 좋음

  - 정리
    - 과거의 데이터를 빠짐없이 가져오거나 실패한 작업 재실행이 필요하면 벌크 형 전송을 사용함

- 스트리밍 형의 데이터 전송
  - 웹 브라우저, 모바일 앱, 디바이스 등에서 계속 발생하는 데이터를 작은 단위로 전송하는 방식
    - 웹 브라우저나 모바일 앱은 HTTP를 사용하고, 디바이스는 MQTT 같은 오버헤드가 작은 프로토콜 사용하기도 함
    - 전송된 데이터는 NoSQL DB에 저장하거나, 메시지 큐/메시지 브로커 같은 중계 시스템으로 전달함
  1. **웹 브라우저**에서의 메시지 배송
     - 전송 효율을 위해 서버에서 데이터를 축적해 두었다가 모아서 전송함
     - 서버 상주형 로그 수집 소프트웨어를 사용하거나, 자바스크립트로 웹 이벤트 추적을 하기도 함
  2. **모바일 앱**으로부터의 메시지 배송
     - HTTP 기반이라 웹 브라우저와 메시지 배송 방식이 유사함
     - MBaaS 사용 또는 모바일 SDK로 이벤트를 축적했다가 온라인 상태일 때 모아서 전송함
     - 통신 불안정으로 재전송, 중복 발생 가능 → 중복 제거 구조 확인 필요
  3. **디바이스**로부터의 메시지 배송
     - 업계 표준이 확실하지 않아 여러 규격이 혼재함
     - MQTT는 일반적으로 Pub/Sub 형 메시지 배송 구조를 가짐
       - Pub는 전달, Sub는 구독의 약자로, 채팅 시스템 / 메시징 앱 / 푸시 알림 등의 시스템에서 자주 사용되는 기술임
       - 메시지의 교환을 중계하는 서버를 MQTT 브로커라 하고, 메시지를 수신하는 시스템을 MQTT 구독자라 함
  - 메시지 배송은 클라이언트 → 프런트엔드 → 메시지 브로커로 전달되고, 이후 저장/처리는 분리해서 진행함

### 4-2. [성능x신뢰성] 메시지 배송의 트레이드 오프

- 메시지 배송의 문제
  - 클라이언트 수가 많아지면 스트리밍 형 메시지 배송에서 **성능**과 **신뢰성**을 동시에 만족시키기 어려움
  - 대량의 메시지를 안정적으로 받기 위해서는 성능이 매우 높고, 성능을 얼마든지 올릴 수 있는 스토리지가 필요함
- 메시지 브로커

  : 데이터량 증가에 대응하기 어렵기 때문에 데이터를 일시적으로 축적하는 중간층
  - 예 :
    - 오픈소스 Apache Kafka(아파치 카프카)
    - 클라우드 서비스 Amazon Kinesis(아마존 키네시스)

- 푸쉬 형과 풀 형
  - 푸쉬 형 : 송신 측의 제어로 데이터를 보내는 방식
  - 풀 형 : 수신 측의 주도로 데이터를 가져오는 방식
  - 메시지 브로커는 푸쉬 형을 풀 형으로 변환하며 속도를 조정함
  - 생산자 : 메시지 브로커에 데이터를 넣는 것(push)
  - 소비자 : 메시지 브로커에서 데이터를 꺼내오는 것(pull)

- 메시지 라우팅
  - 메시지를 소비자가 읽어 처리하며, 복사되어 여러 소비자에게 분배할 수 있음

- 메시지 배송의 신뢰성 보장 방식 세 가지
  - at most once

    : 한 번만 전송(실패 시 결손 발생)
    - 무슨 일이 일어나도 절대로 재전송하지 않음

  - exactly once

    : 손실, 중복 없이 한 번만 전달
    - 통신 내용을 중계하는 코디네이터가 배송을 보장함
      - 두 가지 문제
        - 코디네이터 자체에 문제 있으면 단시간 장애가 발생할 수 있음
        - 코디네이터 판단에만 의존해 시간이 많이 소요될 수 있음

  - at least once

    : 확실히 전달(중복 가능)
    - 재전송으로 중복이 생길 수 있어 **중복 제거**가 필요함
    - 대부분의 메시지 배송 시스템은 'at least once'를 보장하고, 중복 제거는 이용자에게 맡기고 있어 자동으로 중복을 제거해주지 않음

- 중복 제거
  1.  오프셋
      - 덮어쓰는 파일 전송 사고방식과 유사함
      - 벌크 형과 같이 데이터 양이 고정된 경우 잘 작동함
  2.  고유 ID
      - 스트리밍 형의 경우 모든 메시지에 UUID 등의 고유 ID를 지정함
      - 현실적으로 최근에 받은 ID만을 기억하고, 늦게 온 메시지의 중복은 허용함
        - 중복 대부분은 일시적 통신 오류로 인해 발생하므로, 그것만 제거해도 99%의 신뢰도 달성 가능함
      - 종단간(end to end)의 신뢰성
        - 종종 신뢰성보다 **효율**을 중시해, 중간 경로에 'at least once'를 보장하지만, 중복 제거는 하지 않음
        - 신뢰성을 높이려면, 중간 경로를 모두 'at least once'로 통일하고, 클라이언트 상에서 모든 메시지에 고유 ID를 포함하도록 하고 경로 말단에서 중복 제거를 실행해야 함

- 고유 ID를 사용한 중복 제거 두 가지 방법
  1.  분산 스토리지로 NoSQL 데이터베이스 이용
      - 동일한 ID의 데이터는 덮어써서, 중복이 있어도 변화 없음

        -> 자연스럽게 중복 제거됨

  2.  SQL로 중복 제거
      - 일단 객체 스토리지 등에 저장해 놓고, 나중에 읽어 들일 때 중복 제거함
      - 대규모 처리라서 메모리에서 실행 불가능
        -> Hive 같은 배치형 쿼리 엔진에서 실행함

- 데이터 수집의 파이프라인
  - 마지막에 데이터를 구조화하고 열 지향 스토리지로 변환하면, 장기적인 데이터 분석에 적합한 스토리지가 완성됨

- 중복을 고려한 시스템 설계
  - 스트리밍 형 메시지 배송에서는 중간에 명시적으로 중복 제거 방식을 도입하지 않으면 항상 중복이 있을 수 있다고 생각하는 것이 좋음
  - 빅데이터 시스템은 매우 높은 성능을 요구해 아주 작은 중복은 무시하는 경향이 있음
  - 안정된 회선이면 아무것도 안 해도 99% 이상의 신뢰성을 확보할 가능성이 높음

    -> 중복이 있어도 문제가 되지 않도록 시스템을 설계하는 것이 중요함

  - 신뢰성이 중시되는 경우에는 스트리밍 형의 메시지 배송을 피하는 것이 좋음

- 메시지 브로커와 신뢰성
  - 메시지 중복, 결손은 네트워크와 하드웨어의 일시적 장애에 의해 발생함
  - 메시지 브로커는 쓰기 성능이 향상될 뿐만 아니라 후속 처리 안정화에도 도움이 됨
  - 메시지 브로커 자체에 장애가 일어날 수도 있고, 메시지 브로커 안에서 중복이 발생할 가능성도 있음

    -> 시스템을 설계할 때는 '성능'과 '신뢰성'을 양립할 필요가 있음
