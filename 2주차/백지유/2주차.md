# [2주차] 빅데이터를 지탱하는 기술

### 1-1 빅데이터의 정착

- 인터넷 보급 이후, 관계형 데이터베이스(RDB)로는 취급하기 어려운 대량/다양한 데이터가 증가함
- 이를 처리하기 위한 구조(분산 저장/분산 처리/확장성)를 충족하기 위해 Hadoop과 NoSQL이 발전함
- 핵심 흐름은 “온라인에서 쌓고(NoSQL) → 나중에 크게 돌려서 집계(Hadoop)” 쪽으로 굳어짐

### Hadoop

- 다수의 컴퓨터에서 대량의 데이터를 처리하기 위한 분산 처리 시스템
- 수백~수천 대의 컴퓨터를 관리하는 프레임워크(클러스터 운영 전제)
- 프로그래밍 부담을 낮춰 데이터 집계를 수행할 수 있음
→ 분산 시스템을 전문 개발자뿐 아니라 다양한 사용자가 활용할 수 있게 됨
- 대표 구성 요소 예시
    - HDFS: 분산 저장
    - MapReduce: 배치 기반 분산 처리(최근엔 Spark가 많이 대체함)

### NoSQL

- RDB의 제약(스키마 고정, 조인 비용, 수평 확장 한계 등)을 제거하려는 데이터베이스의 총칭
- 고속 읽기/쓰기 가능, 분산 처리에 강함
- 유형
    - Key-Value Store(KVS)
        - 다수의 키와 값을 연관지어 저장
        - 구조가 단순해서 확장과 성능에 유리한 경우가 많음
    - Document Store
        - 복잡한 데이터 구조를 저장(예: JSON)
        - 스키마 유연성이 필요할 때 자주 사용됨
    - Wide-Column Store
        - 여러 키를 사용해 높은 확장성 제공
        - 대규모 분산 환경에서 성능/확장성을 목표로 함

---

## Hadoop + NoSQL

- NoSQL 데이터베이스에 기록하고 Hadoop으로 분산 처리하는 흐름이 정착함
- 효과
    - 현실적인 비용으로 방대한 데이터 처리가 가능해짐
    - NoSQL = 온라인으로 접속하는 데이터베이스(실시간/운영 데이터 축적)
    - Hadoop = 모여진 데이터를 나중에 집계(배치 처리 중심)
- 의미
    - 분산 시스템의 비즈니스 이용이 본격적으로 개척됨

---

## 데이터 웨어하우스(DWH)

- 여러 소스에서 가져온 데이터를 통합해 분석/보고/의사결정을 지원하기 위한 중앙 집중식 저장 시스템
- 분산 시스템의 발전 이후 변화
    - DWH가 사용되는 경우에도 Hadoop을 병행하는 경우가 늘어남
    - 다수의 분석 도구가 대량의 데이터를 보존/집계하기 위해 Hadoop & Hive 사용
    → 이 조합이 “빅데이터 분석 기반”으로 굳어지는 흐름

### 1-1 전통적인 데이터 웨어하우스 단점

- 안정적인 성능을 위해 HW와 SW가 통합 제공되는 경우가 많음
- 데이터 용량 확장이 어렵고 비용이 커지기 쉬움(스케일업 중심의 한계)

### 1-2 Hadoop을 이용한 해결

- Hadoop이 가속도적으로 늘어나는 데이터를 처리함(예: 야간 배치)
- DWH는 중요한 데이터/비교적 작은 데이터 관리에 집중하는 구조로 역할 분담됨

---

## 직접 할 수 있는 데이터 분석 폭 확대

- 클라우드 서비스 보급으로 빅데이터 활용이 증가함
- DWH를 작은 프로젝트 단위에서 구축해 자체적인 데이터 분석 기반을 마련할 수 있음

---

## 데이터 시각화 방법

### 데이터 디스커버리

- 대화형으로 데이터를 시각화해 가치 있는 정보를 찾으려고 하는 프로세스
- 셀프 서비스용 BI 도구
    - BI 도구: DWH와 조합되어 사용된 경영자용 시각화 시스템, 대기업 IT 부서에 도입되는 대규모 도구
    - 셀프 서비스 도구: 개인이 도입할 수 있을 정도로 단순화한 BI 도구

### Apache Spark

- MapReduce보다 효율적인 데이터 처리가 가능한 분산 시스템 프레임워크
- 메모리 기반 처리 구조를 사용해 반복/대화형 분석에서 성능 이점이 커지는 경우가 많음

---

## 빅데이터 시대의 데이터 분석 기반

### 데이터 파이프라인

- 일반적으로 차례대로 전달해나가는 데이터로 구성된 시스템
- 질문: 어디에서 데이터를 수집해 무엇을 실현하고 싶은가?

### 데이터 수집

- 데이터 파이프라인의 시작
- 데이터 전송 방법
    - 벌크형(bulk)
        - 이미 존재하는 데이터를 정리/추출
        - DB나 파일 서버 등에서 정기적으로 데이터 수집
        - ETL/배치 중심으로 관리·재실행이 쉬운 편임
    - 스트리밍형(streaming)
        - 차례대로 생성되는 데이터를 끊임없이 전송
        - 임베디드 장비나 모바일 애플리케이션에서 데이터 수집

### 스트림 처리와 배치 처리

- 모바일 애플리케이션 증가로 벌크형 → 스트리밍형 전송이 늘어남
- 실시간 처리를 위해 스트림 처리 사용
    - 예: 시계열 데이터베이스가 스트림 처리의 결과를 저장해 현재 상황을 즉시 확인 가능
- 3-1 스트림 처리의 단점
    - 장기 데이터 분석에서는 데이터 양이 방대해 비효율적일 수 있음
    - → 배치 처리를 이용하는 경우가 많음

### 분산 스토리지

- 여러 컴퓨터와 디스크로 구성된 스토리지 시스템
- 종류
    - 객체 스토리지: 한 덩어리 데이터에 이름을 부여해 파일로 저장
    - NoSQL: 애플리케이션에서 많은 데이터를 읽고 쓰는 데 성능이 좋음

### 분산 데이터 처리

- 분산 스토리지에 저장된 데이터를 처리하려면 분산 데이터 처리 프레임워크가 필요함
- 데이터 양과 처리 내용에 따라 많은 컴퓨터 자원이 필요함
- 주 역할
    - 나중에 분석하기 쉽도록 데이터를 가공
    - 결과를 외부 데이터베이스에 저장

### SQL 데이터 집계 방법

- 쿼리 엔진
    - 예: Hive
- 대화형 쿼리 엔진
    - Hive보다 고속인 경우가 많음
- DWH 제품 이용
    - ETL 프로세스 필요
    - 분산 스토리지에서 추출한 데이터를 DWH에 적합한 형식으로 변환

### 워크플로 관리

- 전체 데이터 파이프라인의 동작을 관리함
- 정해진 시간에 배치 처리를 스케줄대로 실행
- 오류 발생시 관리자에게 통지함

---

## 데이터 웨어하우스와 데이터 마트

- DWH는 대량의 데이터를 장기 보존하는 것에 최적화됨
- 정리된 데이터를 전송하는 것에 뛰어나지만 소량의 데이터엔 적합하지 않음

### 데이터 흐름 구성

- 데이터 소스
    - 업무 시스템을 위한 RDB 또는 로그를 저장하는 파일 서버
- ETL 프로세스
    - 로우 데이터를 추출/가공한 후 DWH에 저장하는 흐름
- 데이터 마트
    - DWH는 중요한 데이터 처리에 사용되기 때문에 함부로 사용하면 시스템 과부하 발생
    - 데이터 분석 등의 목적으로 사용시 필요한 데이터만 추출해 데이터 마트 구축
    - BI 도구와 조합시키는 형태로 데이터 시각화에 사용 가능
- 데이터 레이크
    - 데이터의 축적 장소
    - 임의의 데이터를 저장할 수 있는 분산 스토리지가 데이터 레이크로 이용됨

---

## 데이터 엔지니어와 데이터 분석가의 역할

- 데이터 엔지니어: 시스템의 구축 및 운용, 자동화
- 데이터 분석가: 데이터에서 가치 있는 정보 추출

---

## 애드 혹 분석 및 대시보드 도구

- 애드 혹 분석: 자동화를 생각하지 않고 수작업으로 데이터 집계, 일회성 데이터 분석
- 대시보드 도구: 데이터 마트 없이 동작

---

## 데이터 수집 목적

- 데이터 검색
- 데이터 가공
- 데이터 시각화

---

## 4장

### 4-1 벌크형과 스트리밍형 데이터 수집

- 객체 스토리지
    - 대량으로 파일을 저장하기 위한 확장성이 높은 분산 스토리지
    - Hadoop HDFS, 클라우드 서비스 Amazon S3
    - 데이터의 읽고 쓰기를 하드웨어에 분산해 데이터 양이 늘어나도 성능이 떨어질 수 없도록 함
    - 데이터양이 많을 때 우수하나 소량의 데이터에서 비효율적
- 데이터 수집
    - 수집한 데이터를 가공하여 집계 효율이 좋은 분산 스토리지를 만드는 일련의 프로세스
    - 데이터 수집, 구조화 데이터 작성, 분산 스토리지에 대한 장기적인 저장 등
- 벌크형 데이터 전송
    - 전통적인 데이터 웨어하우스에서 사용
    - ETL 서버에 구조화된 데이터 처리에 적합한 데이터 웨어하우스를 위한 ETL 도구 사용
- 데이터 전송의 워크플로
    - 데이터 전송의 신뢰성이 중요한 경우 벌크형 도구 사용
    - 문제 발생 시 데이터 전송 재실행 가능
    - 워크플로 관리 도구와 궁합이 뛰어남
- 스트리밍형 데이터 전송
    - 각종 디바이스(웹 브라우저, 모바일 앱 등)에서 데이터를 수집하는 경우
    - 메시지 배송 시스템은 전송되는 양에 비해 통신을 위한 오버헤드가 커져 높은 성능 요구
    - 메시지 저장 방법: NoSQL 사용 / 메시지 큐, 메시지 브로커 등의 중계 시스템에 전송
- 웹 브라우저에서의 메시지 배송
    - 웹 서버 안에서 메시지를 만들어 축적 후 배송
    - 웹 이벤트 추적(자바스크립트로 웹 브라우저에서 직접 메시지 전송) 이용
- 모바일 앱으로부터의 메시지 배송
    - 웹 브라우저와 동일한 흐름
    - 모바일 앱에 특화된 엑세스 해석 서비스로 데이터 수집 후 개발키트로 전송
- 디바이스로부터의 메시지 배송
    - MQTT: Pub/Sub 형 메시지 배송(전달과 구독)

---

### 4-2 메시지 배송의 트레이드오프

- 메시지 브로커
    - 대량의 메시지를 안정적으로 받기 위해 데이터를 일시적으로 축적하는 중간 계층
    - push: 송신 측 제어로 데이터를 보냄
    - pull: 수신 측 주도로 데이터를 가져옴
    - 메시지 브로커가 push → pull 메시지 배송 타이밍을 변환함
- 메시지 라우팅
    - 데이터 메시지를 생성된 위치(발신자)에서 최종 목적지(수신자)까지 가장 효율적이고 정확하게 전달하도록 경로를 결정하고 보내는 프로세스
- 스트림 처리
    - 짧은 간격으로 차례대로 데이터를 꺼내서 처리하는 것
- 메시지 배송의 신뢰성 문제
    - 메시지 중복이나 누락으로 인한 신뢰성 문제
    - at most once: 메시지가 한 번 전송되나 전송에 실패해 결손 가능성이 있음
    - exactly once: 메시지가 손실되거나 중복 없이 한 번만 전달됨
    - at least once: 메시지는 확실히 전달되나 여러 번 전달될 수 있음
- 중복 제거 방법
    - 오프셋 이용
        - 전송해야 할 데이터에 파일명 등의 이름을 부여해 작은 메시지에 실어 배송함
        - 벌크형 같이 데이터양이 고정된 경우 잘 작동함
    - 고유 ID에 의한 중복 제거
        - 모든 메시지에 UUID 등의 고유 ID 지정
        - 최근 받은 ID만 기억해두고 늦게 온 메시지의 중복 허용
        - 스트리밍형에서 사용
        - NoSQL / SQL

---

### 4-3 시계열 데이터의 최적화

- 프로세스 시간과 이벤트 시간
    - 이벤트 시간: 클라이언트 상에서 메시지가 생성된 시간
    - 프로세스 시간: 서버가 처리하는 시간
- 프로세스 시간에 의한 분할과 문제점
    - 풀 스캔: 다수의 파일을 모두 검색하는 쿼리로 시스템 부하를 높임
    - 데이터가 파일 생성 시간 기준으로 저장될 수 있음
    - 동일 이벤트 시간이 여러 파일에 분산될 수 있음
    - 특정 날짜 데이터 조회 시 다수의 파일을 열어야 함
    - 정확한 집계를 위해 풀 스캔이 발생함
    - 쿼리 성능이 저하됨
- 이벤트 시간 취급을 효율화하기 위한 데이터 정렬
    - 이벤트 시간에 대해 인덱스를 만들기
        - 시계열 인덱스를 사용해 짧은 범위의 특정 시간 데이터 집계를 빠르게 실행 가능
    - 새로 도착한 데이터를 배치 처리로 변환하기
        - 이벤트 시간으로 데이터를 정리한 후 열 지향 스토리지로 변환함
        - 읽어들이는 데이터 양을 최소화하도록 정렬함
        - 조건절 푸시다운으로 필요한 최소 데이터만 읽도록 최적화함
- 이벤트 시간 기준 분할(시계열 테이블)
    - 이벤트 발생 시간을 기준으로 데이터를 분할함
    - 테이블을 물리적으로 나누는 테이블 파티셔닝 방식임
    - 시간 기준으로 분할된 테이블을 시계열 테이블이라 함
    - 이벤트 발생 시간을 기준으로 파티션을 생성함
    - 파티션 이름에 이벤트 날짜를 포함함(예: `event_0101`)
    - 이벤트 도착 시점과 관계없이 발생 시간이 1월 1일이면 `event_0101`에 저장함
- 효과
    - 특정 날짜 이벤트는 하나의 파티션에만 존재함
    - 조회 시 필요한 파티션만 접근함
    - 불필요한 파일 접근이 제거됨
    - 쿼리 성능이 향상됨
- 구현 시 주의점
    - 과거 이벤트 시간이 늦게 도착할 수 있음
    - 각 파티션에 매일 소량의 데이터가 추가됨
    - 작은 파일이 다수 생성될 수 있음
    - 관리하지 않으면 분산 스토리지 및 쿼리 성능이 저하될 수 있음
- 보완 아이디어
    - 시계열 데이터에 적합한 분산 데이터베이스 사용
    - 오래된 데이터는 삭제 또는 아카이빙 정책 적용

---

### 4-4 비구조화 데이터의 분산 스토리지

- NoSQL 데이터베이스에 의한 데이터 활용
    - 분산 스토리지에는 확장성과 유연성이 요구됨
    - 구조화하지 않고 저장할 수 있어야 함
- 객체 스토리지 단점
    - 객체 스토리지 상 파일은 교체가 어려움
    - 쓰기 빈도가 높은 데이터는 별도 RDB 또는 다른 분산 DB에 저장하는 편이 유리함
    - 객체 스토리지에 저장된 데이터는 집계까지 시간이 걸릴 수 있음
- NoSQL 데이터베이스의 예
    - 분산 KVS
        - 모든 데이터를 키-값 쌍으로 저장하도록 설계됨
        - 키가 정해지면 어느 노드에 배치할지 결정함
        - 노드 간 부하를 균등하게 분산함
        - 노드 증감만으로 클러스터 성능을 변경할 수 있음
        - 예: Amazon DynamoDB
    - 와이드 칼럼 스토어
        - 분산 KVS를 발전시켜 2개 이상의 임의 키로 저장할 수 있게 함
        - 예: Google Cloud Bigtable, Apache HBase, Apache Cassandra
        - 내부적으로 행 키와 칼럼 명의 조합에 대해 값을 저장함
        - 예: Apache Cassandra
    - 도큐먼트 스토어
        - 복잡하게 얽힌 스키마리스 데이터를 그대로 저장하고 쿼리를 실행할 수 있게 함
        - 예: MongoDB
    - 검색 엔진
        - 저장된 데이터를 쿼리로 찾아내고 텍스트/스키마리스 데이터를 집계하는 데 자주 사용됨
        - 역색인을 만들어 키워드 검색을 고속화함
        - 단, 시스템 부하 및 디스크 소비량이 커질 수 있음
