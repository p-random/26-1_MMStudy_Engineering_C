# 3주차 정리

**빅데이터를 지탱하는 기술 - 니시다 케이스케**

- 3주차 범위 : 143p ~ 153p(4-2), 161p ~ 175p(4-4)

# CHAPTER4 - 빅데이터의 축적

# **4-2. 이상적인 exactly-once를 거의 쓰지 않는 진짜 이유**

## **왜 exactly-once가 ‘근본적으로’ 어렵다고 말하나**

2015년, 분산 시스템 엔지니어 Tyler Treat의 글 
*“You Cannot Have Exactly-Once Delivery”* 는 분산 시스템에서 exactly-once 전달은 불가능하다고 주장한다.

그 이유는 분산 환경에서 다음 상황들을 **완전히 구분할 수 없기 때문**이다.

- 메시지가 유실된 것인지
- ack(확인 응답)이 유실된 것인지
- 상대 노드가 느린 것인지
- 상대 노드가 장애가 난 것인지

즉, “상대가 받았는지/처리했는지”를 100% 확신할 방법이 없어서

모든 장애 상황에서 정확히 한 번 전달을 보장하는 것은 근본적으로 어렵다는 주장이다.

## **그래서 실무는 at-least-once를 기본으로 둔다**

많은 메시징 시스템은 “전달 보장”을 제공할 때, 기본적으로 at-least-once를 내세운다.

> Every major message queue in existence which provides any guarantees will market itself as at-least-once delivery.
> 

> “전달 보장을 제공하는 대부분의 주요 메시징 시스템은, 자신들이
> **at-least-once(적어도 한 번)** 전달을 제공한다고 홍보한다.”
> 

따라서 exactly-once를 주장하는 경우는

- 마케팅을 위한 과장일 수도 있고
- 분산 시스템 제약을 충분히 고려하지 않은 주장일 수도 있다.



## **실무에서 exactly-once를 ‘흉내내는’ 방법**

현실적인 접근은 exactly-once 자체를 “완벽히 구현”하기보다,

**중복이 있다고 전제해서** 결과적으로 “exactly-once처럼 보이게” 만드는 것이다.

- **멱등성(idempotency)**
    - 동일 메시지가 여러 번 처리되어도 결과가 동일하도록 설계
- **중복 제거(deduplication)**
    - 메시지 ID 등을 활용해 중복 처리 결과를 제거



## **Kafka의 Exactly-Once Semantics(EOS)는 “카프카가 통제하는 범위”에서만 가능하다**

Kafka의 EOS는 “어떤 상황에서도 무조건 정확히 한 번 전달”을 의미하지 않는다.

대신 Kafka가 통제할 수 있는 구간에서는 **중복이 결과에 반영되지 않게** 해서 **한 번만 처리된 것처럼** 보이게 만든다.

Kafka 파이프라인은 상황에 따라 아래 3구간으로 나눠 볼 수 있다.

### **1) Producer → Topic (Kafka에 쓰기)**

> Producer가 토픽에 메시지를 쓰는 단계
> 
- 네트워크가 불안정하면 **프로듀서가 “저장 성공했는지” 확신을 못 해서 같은 메시지를 다시 보낼 수 있다.**
- 그러면 토픽에 **같은 메시지가 두 번 저장**될 수 있다.
- 그래서 카프카는 **멱등성 프로듀서**로 **“다시 보내도 한 번만 저장”** 되게 할 수 있다.

### **2) Topic → Consumer → Producer → Topic (Kafka 안에서 읽고 다시 쓰기)**

> **토픽에서 메시지를 읽고 처리한 뒤, 다른 토픽에 결과를 다시 쓰는 단계**
> 
- 처리 앱은 보통 이렇게 한다:
    
    **읽기 → 처리 → 결과를 다른 토픽에 쓰기 → “여기까지 읽었다” 표시(오프셋 커밋)**
    
- 그런데 앱이 중간에 죽거나 순서가 꼬이면
    
    **결과는 두 번 쓰이거나(중복), 아예 안 쓰인 것처럼(누락)** 보일 수 있다.
    
- 그래서 카프카는 **트랜잭션**으로
    
    **“결과 쓰기 + 오프셋 커밋”을 한 묶음으로 처리**해서
    
    **실패해도 전체가 딱 한 번 처리된 것처럼** 만들 수 있다.
    

### **3) Topic → Consumer → 외부 DB (Kafka 밖으로 쓰기)**

> **읽은 결과를 외부 DB에 저장하는 단계**
> 
- 카프카의 트랜잭션은 **DB까지 자동으로 같이 묶어주지 못하는 경우가 많다.**
- 그래서 이 구간은 보통 DB에서
    
    **유니크 키(중복 금지) / upsert(없으면 넣고, 있으면 덮어씀) / 멱등성 키(중복 처리 방지)** 같은 방식으로 **중복 저장을 막는다.**
    

        → Kafka의 EOS는 “완벽한 exactly-once”가 아니라,
          Kafka 내부에서 가능한 범위만 exactly-once에 가깝게 만든다.



## **정리**

- exactly-once는 이상적이지만, 분산 환경에서는 “받았는지/처리했는지”를 확신하기 어려워 근본적으로 어렵다는 주장이 있다.
- 그래서 실무는 at-least-once를 기본으로 두고, 멱등성/중복 제거로 exactly-once에 가까운 효과를 만든다.
- Kafka의 EOS도 “모든 경우의 exactly-once”가 아니라 **지원 가능한 구간이 정해져 있다.**



   

# **4-4. CQL vs SQL — 어떻게 다를까?**


- 와이드 칼럼 스토어 챕터에 예시로 나온 Apache Cassandra에서 사용하는 CQL(Cassandra Query Language)은 Cassandra에서 데이터를 조회/수정하기 위해 사용하는 쿼리 언어다.
- CQL은 SQL처럼 생겼지만, Cassandra는 데이터를 **여러 DB 서버(노드)에 나눠 담는 분산 DB**라 데이터가 한 곳에 모여 있지 않다.

이 구조에서는 데이터를 모아 계산하는 기능(JOIN 등)이 부담이 크다.

그래서 CQL은 **“키로 찍어서 빠르게 가져오는 쿼리”** 중심으로 설계되었다.


## **1) Partition Key가 핵심이다**

- Cassandra는 데이터를 **Partition Key 기준으로 묶어(= Partition)** 저장한다.
- Partition은 “같은 Partition Key 값을 가진 행들의 묶음”이다.

    → 그래서 조회할 때 Partition Key를 알면

    데이터가 있는 노드를 **바로 찾아가서** 빠르게 읽을 수 있다.



## **2) 그래서 SQL에서 당연한 기능이 없다**

- SQL의 JOIN은 여러 테이블에서 데이터를 모아 조합한다.
- 그런데 분산 환경에서는 데이터가 여러 노드에 흩어져 있어
    
    “모으는 과정” 자체가 느리고 복잡해질 수 있다.
    

그래서 Cassandra는 문서에서 다음 기능을 제공하지 않는다고 명시한다.

- **분산 JOIN**
- **파티션 간 트랜잭션**
- **FK(외래키)**



## **3) 대신 설계 방식이 바뀐다**

SQL은 정규화해 두고 JOIN으로 조합하는 방식이 흔하다.

반면 Cassandra는 JOIN이 없으므로,

- 원하는 조회 형태에 맞춰
- 테이블을 따로 구성(비정규화/중복 포함)
- **Partition Key 기반으로 빠르게 읽히게**

설계하는 방향으로 접근한다.



## **결론**

> **CQL은 SQL처럼 보이지만, 
JOIN 같은 전역 연산 대신 “Partition Key로 노드를 바로 찾아가 조회”하는 방식에 최적화된 쿼리 언어다.**
>